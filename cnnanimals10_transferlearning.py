# -*- coding: utf-8 -*-
"""CnnAnimals10_TransferLearning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vNUsm4hEMnyr64gBFUwe44KRLQdcSfrx
"""

#!pip install kagglehub

import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
import os
from tensorflow.keras import layers, models
import kagglehub
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
import random  # Biblioteca para realizar operaciones aleatorias
from sklearn.metrics import  classification_report
from tensorflow.keras.preprocessing.image import ImageDataGenerator 
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay



dataset_path = kagglehub.dataset_download("alessiocorrado99/animals10")

RAW_IMG_PATH = '/root/.cache/kagglehub/datasets/alessiocorrado99/animals10/versions/2/raw-img/'

# Imprimir la estructura inicial del dataset
print("Estructura inicial del dataset:")
# Recorrer cada subcarpeta (clase) dentro de "raw-img"
for class_name in os.listdir(RAW_IMG_PATH):
    class_path = os.path.join(RAW_IMG_PATH, class_name)  # Ruta completa de la clase
    # Contar el número de imágenes en cada subcarpeta
    print(f"Clase: {class_name}, Número de imágenes: {len(os.listdir(class_path))}")

# Establecer un límite de 1400 imágenes por clase
LIMIT_IMAGES = 1400

# Recorrer cada subcarpeta (clase) dentro de "raw-img"
for class_name in os.listdir(RAW_IMG_PATH):
    class_path = os.path.join(RAW_IMG_PATH, class_name)  # Ruta completa de la clase
    if os.path.isdir(class_path):  # Asegurarse de que sea un directorio (y no un archivo)
        images = os.listdir(class_path)  # Listar todas las imágenes en la carpeta
        random.shuffle(images)  # Mezclar aleatoriamente las imágenes
        # Eliminar las imágenes que excedan el límite establecido (1400)
        for img in images[LIMIT_IMAGES:]:
            os.remove(os.path.join(class_path, img))  # Eliminar la imagen

# Verificar la estructura después de limitar las imágenes
print("\nEstructura del dataset después de limitar las imágenes:")
for class_name in os.listdir(RAW_IMG_PATH):
    class_path = os.path.join(RAW_IMG_PATH, class_name)  # Ruta completa de la clase
    print(f"Clase: {class_name}, Imágenes: {len(os.listdir(class_path))}")  # Contar imágenes restantes

#plt.imshow(images[1400])  # Changed 'data' to 'train_features'
#plt.title(translate[list(translate.keys())[labels[1400]]]) # Changed 'class_names' to 'translate' keys and 'labels' to 'train_labels'
#plt.show()

 # Generador de datos para imágenes

# Tamaño de las imágenes para redimensionarlas a 128x128
IMAGE_SIZE = (128, 128)
BATCH_SIZE = 64  # Tamaño de lote (cantidad de imágenes procesadas en cada paso)

# Configuración del generador de datos para entrenamiento y validación
train_datagen = ImageDataGenerator(
    rescale=1.0 / 255,      # Escalar los valores de los píxeles a un rango entre 0 y 1
    rotation_range=10,      # Rotar las imágenes hasta 10 grados
    width_shift_range=0.1,  # Desplazar horizontalmente hasta un 10%
    height_shift_range=0.1, # Desplazar verticalmente hasta un 10%
    shear_range=0.1,        # Transformación de corte en hasta un 10%
    zoom_range=0.1,         # Zoom aleatorio en hasta un 10%
    horizontal_flip=True,   # Invertir horizontalmente (útil para datos no direccionales)
    fill_mode='nearest',    # Cómo rellenar píxeles vacíos creados por transformaciones
    validation_split=0.3    # Dividir el dataset en 80% entrenamiento y 20% validación
)



# Crear el generador de datos para el conjunto de entrenamiento
train_generator = train_datagen.flow_from_directory(
    RAW_IMG_PATH,  # Ruta a la carpeta que contiene las subcarpetas de clases
    target_size=IMAGE_SIZE,  # Redimensionar imágenes a 128x128
    batch_size=BATCH_SIZE,  # Procesar imágenes en lotes de 32
    class_mode='categorical',  # Salida categórica para clasificación (10 clases)
    subset='training'  # Subconjunto de entrenamiento
)

# Crear el generador de datos para el conjunto de validación
val_generator = train_datagen.flow_from_directory(
    RAW_IMG_PATH,  # Mismo directorio que el conjunto de entrenamiento
    target_size=IMAGE_SIZE,  # Redimensionar imágenes a 128x128
    batch_size=BATCH_SIZE,  # Procesar imágenes en lotes de 32
    class_mode='categorical',  # Salida categórica para clasificación (10 clases)
    subset='validation'
)

# Obtener un lote de datos del generador de entrenamiento
images, labels = next(train_generator)  # Extrae un lote de imágenes y etiquetas

# Crear una cuadrícula para mostrar imágenes (por ejemplo, 3x3)
fig, axes = plt.subplots(3, 3, figsize=(10, 10))  # Mostrar 9 imágenes (3x3)
axes = axes.ravel()  # Convertir el arreglo en una lista para iterar fácilmente

for i in range(9):  # Mostrar las primeras 9 imágenes del lote
    axes[i].imshow(images[i].squeeze())
    label = np.argmax(labels[i])  # Obtener el índice de la clase (si las etiquetas son one-hot encoded)
    axes[i].set_title(f'Clase: {label}')  # Título con la clase
    axes[i].axis('off')  # Ocultar los ejes para mayor claridad

plt.tight_layout()
plt.show()


# Cargar el modelo VGG16 preentrenado sin las capas finales
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))

# Congelar las capas del modelo base
base_model.trainable = False


model = models.Sequential()

# Añadir el modelo preentrenado como extractor de características
model.add(base_model)


# Añadir una capa de Global Average Pooling para reducir dimensionalidad
model.add(layers.GlobalAveragePooling2D())



# Capa densa completamente conectada
model.add(layers.Dense(256, activation='relu'))  # Densa con 256 neuronas
model.add(layers.Dropout(0.20))  # Dropout para evitar sobreajuste

# Capa de salida (Softmax para clasificación multiclase)
model.add(layers.Dense(10, activation='softmax'))

model.summary()

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Entrenamiento del modelo
# Entrenar el Modelo
history = model.fit(
    train_generator,  # Generador de datos de entrenamiento
    epochs=30,  # Número de épocas (veces que el modelo verá todo el dataset)
    validation_data=val_generator  # Generador de datos de validación
)

print(history)
# Guardado del modelo
#model.save('animal_model.keras')
#model.save_weights('animal_model_weights.weights.h5')

# Obtener un lote de imágenes del generador de validación
images, labels = next(val_generator)

# Realizar predicciones
predictions = model.predict(images)
predicted_labels = np.argmax(predictions, axis=1)  # Etiquetas predichas
true_labels = np.argmax(labels, axis=1)  # Etiquetas reales

# Diccionario de clases
class_indices = train_generator.class_indices
classes = list(class_indices.keys())

# Mostrar imágenes con etiquetas reales y predichas
plt.figure(figsize=(12, 12))
for i in range(9):  # Mostrar las primeras 9 imágenes
    plt.subplot(3, 3, i + 1)
    plt.imshow(images[i])
    plt.title(f"Real: {classes[true_labels[i]]}\nPred: {classes[predicted_labels[i]]}")
    plt.axis('off')
plt.tight_layout()
plt.show()


# Crear arreglos para etiquetas
y_true = np.array([])
y_pred = np.array([])

# Procesar todos los datos de validación
for images, labels in val_generator:
    predictions = model.predict(images)  # Predicciones del modelo
    y_true = np.concatenate([y_true, np.argmax(labels, axis=1)])  # Etiquetas reales
    y_pred = np.concatenate([y_pred, np.argmax(predictions, axis=1)])  # Etiquetas predichas

    # Romper el bucle cuando se complete el generador
    if len(y_true) >= val_generator.samples:  # `samples` indica el total de muestras en el generador
        break

# Generar la matriz de confusión
cm = confusion_matrix(y_true, y_pred)

# Etiquetas de las clases (extraídas del generador)
classes = list(val_generator.class_indices.keys())

# Crear una instancia de ConfusionMatrixDisplay
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)

# Visualizar la matriz de confusión
plt.figure(figsize=(10, 8))
disp.plot(cmap=plt.cm.Blues, ax=plt.gca())
plt.title("Matriz de Confusión")
plt.show()

# Visualizar las métricas de entrenamiento y validación

# Graficar la pérdida
plt.plot(history.history['loss'], label='Pérdida de Entrenamiento')
plt.plot(history.history['val_loss'], label='Pérdida de Validación')
plt.legend()
plt.title('Pérdida')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.show()

# Graficar la precisión
plt.plot(history.history['accuracy'], label='Precisión de Entrenamiento')
plt.plot(history.history['val_accuracy'], label='Precisión de Validación')
plt.legend()
plt.title('Precisión')
plt.xlabel('Épocas')
plt.ylabel('Precisión')
plt.show()


# Generar el reporte de clasificación
report = classification_report(y_true, y_pred, target_names=classes)
print("Reporte de Clasificación:")
print(report)